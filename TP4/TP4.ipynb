{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05f27426-cf6e-48f4-bd8c-fd6e16829bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CARGAR LAS BASES DE DATOS\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "#os.chdir('C:/Users/Nacha/OneDrive/Desktop/Anaconda/TP4')\n",
    "#os.chdir('C:/Flor/UDESA/Primavera 2024/Ciencia de datos/TP4')\n",
    "os.chdir('/Users/trinimoran/Documents/Ciencia de Datos/CC408-T13/TP4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2173621",
   "metadata": {},
   "source": [
    "Parte I: Análisis de la base de hogares y tipo de ocupación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcd05fe",
   "metadata": {},
   "source": [
    "## PUNTO 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39e3857-b816-4a73-b88f-cefb56b0aa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "hogar_24 = pd.read_excel('usu_hogar_T124.xlsx')\n",
    "hogar_04 = pd.read_stata('Hogar_t104.dta')\n",
    "eph_24 = pd.read_excel('usu_individual_T124.xlsx')\n",
    "eph_04 = pd.read_stata('Individual_t104.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0329bca4-bad0-4f79-9f22-d1f1fa8a0cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiamos los nombres de las columnas a mayúsculas\n",
    "hogar_04.columns = hogar_04.columns.str.upper()\n",
    "hogar_24.columns = hogar_24.columns.str.upper()\n",
    "eph_04.columns = eph_04.columns.str.upper()\n",
    "eph_24.columns = eph_24.columns.str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454e27bb",
   "metadata": {},
   "source": [
    "Eliminamos las observaciones que no corresponden a CABA o al Gran Buenos Aires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2c7090-aec9-4713-8962-df98c3cc68e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dejamos los datos individuales que tengan solo de CABA y GBA\n",
    "eph_04_cleaned = eph_04.loc[eph_04['AGLOMERADO'].isin(['Ciudad de Buenos Aires', 'Partidos del GBA'])].copy()\n",
    "eph_04_cleaned['AGLOMERADO'] = eph_04_cleaned['AGLOMERADO'].replace({'Ciudad de Buenos Aires': 'CABA', 'Partidos del GBA': 'GBA'})\n",
    "\n",
    "eph_24_cleaned = eph_24.loc[eph_24['AGLOMERADO'].isin([32, 33])].copy()\n",
    "eph_24_cleaned['AGLOMERADO'] = eph_24_cleaned['AGLOMERADO'].replace({32: 'CABA', 33: 'GBA'})\n",
    "\n",
    "\n",
    "#Dejamos los datos de los hogares que tengan solo de CABA y GBA\n",
    "hogar_04_cleaned = hogar_04.loc[hogar_04['AGLOMERADO'].isin(['Ciudad de Buenos Aires', 'Partidos del GBA'])].copy()\n",
    "hogar_04_cleaned['AGLOMERADO'] = hogar_04_cleaned['AGLOMERADO'].replace({'Ciudad de Buenos Aires': 'CABA', 'Partidos del GBA': 'GBA'})\n",
    "\n",
    "hogar_24_cleaned = hogar_24.loc[hogar_24['AGLOMERADO'].isin([32, 33])].copy()\n",
    "hogar_24_cleaned['AGLOMERADO'] = hogar_24_cleaned['AGLOMERADO'].replace({32: 'CABA', 33: 'GBA'})\n",
    "\n",
    "\n",
    "# Verificamos las dimensiones después del filtro\n",
    "print(\"Datos hogares 2004 después de filtrar:\", hogar_04_cleaned.shape[0])\n",
    "print(\"Datos hogares 2024 después de filtrar:\", hogar_24_cleaned.shape[0])\n",
    "print(\"Datos individuales 2004 después de filtrar:\", eph_04_cleaned.shape[0])\n",
    "print(\"Datos individuales 2024 después de filtrar:\", eph_24_cleaned.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bef96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aseguramos que CODUSU sea string y NRO_HOGAR sea numérico en todas las bases\n",
    "for df in [eph_04_cleaned, hogar_04_cleaned, eph_24_cleaned, hogar_24_cleaned]:\n",
    "    df['CODUSU'] = df['CODUSU'].astype(str)  # Convertimos CODUSU a string\n",
    "    df['NRO_HOGAR'] = df['NRO_HOGAR'].astype(int)  # Convertimos NRO_HOGAR a entero\n",
    "\n",
    "# Comprobamos si hay valores nulos en las claves\n",
    "for name, df in zip(['eph_04', 'hogar_04', 'eph_24', 'hogar_24'], \n",
    "                    [eph_04_cleaned, hogar_04_cleaned, eph_24_cleaned, hogar_24_cleaned]):\n",
    "    print(f\"Valores nulos en {name}:\")\n",
    "    print(df[['CODUSU', 'NRO_HOGAR']].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e65d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dejamos todos los datos relevantes (que usamos después) codificados de la misma forma\n",
    "eph_04_cleaned['CH04'] = eph_04_cleaned['CH04'].replace({'Varón': 1, 'Mujer': 2})\n",
    "eph_04_cleaned['CH07'] = eph_04_cleaned['CH07'].replace({'Unido': 1, 'Casado': 2, 'Separado o divorciado': 3, 'Viudo': 4, 'Soltero': 5})\n",
    "eph_04_cleaned['CH08'] = eph_04_cleaned['CH08'].replace({'Obra social (incluye PAMI)': 1, 'Mutual/Prepaga/Servicio de emergencia': 2, 'Planes y seguros públicos': 3, 'No paga ni le descuentan': 4, 'Ns./Nr.': 9,'Obra social y mutual/prepaga/servicio de emergencia': 12, 'Obra social y Planes y Seguros Públicos': 13, 'Mutual/prepaga/servicio de emergencia/planes y seguros públi': 23, 'Obra social, mutual / prepaga / servicio de emergencia y Planes y Seguros Públicos': 123}) \n",
    "eph_04_cleaned['NIVEL_ED'] = eph_04_cleaned['NIVEL_ED'].replace({'Primaria Incompleta (incluye educación especial)': 1, 'Primaria Completa': 2, 'Secundaria Incompleta': 3, 'Secundaria Completa': 4, 'Superior Universitaria Incompleta': 5, 'Superior Universitaria Completa':6, 'Sin instrucción': 7, 'Ns./Nr.':9})\n",
    "eph_04_cleaned['ESTADO'] = eph_04_cleaned['ESTADO'].replace({'Entrevista individual no realizada (no respuesta al cuestion': 0, 'Ocupado': 1, 'Desocupado': 2, 'Inactivo': 3, 'Menor de 10 años':4}) \n",
    "eph_04_cleaned['CAT_INAC'] = eph_04_cleaned['CAT_INAC'].replace({'Jubilado/pensionado': 1, 'Rentista': 2, 'Estudiante': 3,'Ama de casa': 4, 'Menor de 6 años': 5, 'Discapacitado': 6, 'Otros':7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644d707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar columnas en las bases antes del merge\n",
    "print(\"Columnas en eph_04_cleaned:\", eph_04_cleaned.columns.tolist())\n",
    "print(\"Columnas en hogar_04_cleaned:\", hogar_04_cleaned.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f0ebc0",
   "metadata": {},
   "source": [
    "Unimos la base de la encuesta individual con la encuesta de hogares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c724e6-2e32-4ed4-a497-764047228c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge para 2004\n",
    "data_2004 = eph_04_cleaned.merge(hogar_04_cleaned, on=['CODUSU', 'NRO_HOGAR'], how='inner')\n",
    "print(\"Datos combinados para 2004:\", data_2004.shape)\n",
    "\n",
    "# Merge para 2024\n",
    "data_2024 = eph_24_cleaned.merge(hogar_24_cleaned, on=['CODUSU', 'NRO_HOGAR'], how='inner')\n",
    "print(\"Datos combinados para 2024:\", data_2024.shape)\n",
    "\n",
    "# Combinamos los dos años\n",
    "data = pd.concat([data_2004, data_2024], ignore_index=True)\n",
    "print(\"Datos finales combinados:\", data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d27047e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32cc6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Como vemos que algunas columnas se crearonn dobles, hacemos arreglos para que sean una sola\n",
    "# Creamos una lista para las nuevas columnas combinadas\n",
    "combined_columns = []\n",
    "\n",
    "# Identificamos las columnas que tienen sufijos '_x'\n",
    "columns_to_merge = [col for col in data.columns if col.endswith('_x')]\n",
    "\n",
    "# Iteramos sobre las columnas y combinarlas\n",
    "for col in columns_to_merge:\n",
    "    col_y = col.replace('_x', '_y')\n",
    "    \n",
    "    # Combinamos las columnas (dando prioridad a los valores de '_x')\n",
    "    data[col.replace('_x', '')] = data[col].combine_first(data[col_y])\n",
    "    \n",
    "    # Añadimos las columnas combinadas a la lista\n",
    "    combined_columns.append(col.replace('_x', ''))\n",
    "\n",
    "# Eliminamos las columnas duplicadas\n",
    "data.drop([col for col in data.columns if col.endswith('_x') or col.endswith('_y')], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d497ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estamos creando esta copia por la advertencia de la línea anterior\n",
    "final_data = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5de1a62",
   "metadata": {},
   "source": [
    "## PUNTO 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cd6ac8-028e-453a-9c23-063d9964b309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos las observaciones con datos que no tienen sentido \n",
    "# CH06: edad\n",
    "# PP03D: cantidad de ocupaciones \n",
    "# PP08D1: Monto por sueldos / jornales, salario familiar, horas extras, otras bonificaciones habituales y tickets, vales o similares percibidos en el mes de referencia \n",
    "# P21: MONTO DE INGRESO DE LA OCUPACIÓN PRINCIPAL \n",
    "# IPCF: ingreso per cápita familiar\n",
    "# IX_TOT: cantidad de personas en un hogar\n",
    "# Convertimos las columnas relevantes a tipo numérico\n",
    "cols_to_convert = ['CH06', 'PP03D', 'PP08D1', 'P21','IPCF', 'IX_TOT', 'CAT_INAC']\n",
    "final_data[cols_to_convert] = final_data[cols_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Eliminamos las observaciones con datos que no tienen sentido \n",
    "final_data.drop(final_data[(final_data['CH06'] < 0) | (final_data['PP03D'] < 0) | (final_data['PP08D1'] < 0) | (final_data['P21'] < 0)| (final_data['IPCF'] < 0)| (final_data['IX_TOT'] < 0)| (final_data['CAT_INAC'] < 0)].index, inplace=True)\n",
    "\n",
    "# Imprimimos la cantidad de datos restantes después de la limpieza\n",
    "print(\"Cantidad de datos después de la limpieza:\", len(final_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1f1efd-d7e1-48fb-a282-5c83b25c228d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cantidad de NaN en edad:', final_data['CH06'].isna().sum())\n",
    "\n",
    "# Crearmos una copia de final_data solo con las columnas deseadas\n",
    "# pero saco edad porque se me va a mezclar la edad 9\n",
    "cols = ['CH04', 'CH07', 'CH08', 'NIVEL_ED', 'ESTADO', 'CAT_INAC', 'IPCF', 'IX_TOT']\n",
    "data_nsnr = final_data[cols].copy()\n",
    "\n",
    "# Reemplazar los valores 9, 99, 999, y 9999 por NaN\n",
    "data_nsnr.replace([9, 99, 999, 9999], np.nan, inplace=True)\n",
    "\n",
    "# Mostrar un conteo de valores NaN en cada columna\n",
    "na_columna = data_nsnr.isna().sum()\n",
    "print(\"Cantidad de valores no saben/no responde (ahora NaN) por columna:\")\n",
    "print(na_columna)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14e9536",
   "metadata": {},
   "source": [
    "DATOS FALTANTES: 135 en edad, 13 en estado civil (CH07), 20 en cobertura medica (CH08), 1 en ingreso per capita familiar Y 230 en IX_TOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb2e606-ba39-4797-8644-b4b86d8ad4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos que la columna 'CH06' sea numérica\n",
    "final_data.loc[:, 'CH06'] = pd.to_numeric(final_data['CH06'], errors='coerce')\n",
    "\n",
    "# Calculamos la mediana de la edad por nivel educativo\n",
    "edad_por_nivel = final_data.groupby('NIVEL_ED')['CH06'].median()\n",
    "\n",
    "# Definimos una función para rellenar NaN basándose en el nivel educativo\n",
    "def rellenar_nan_edad(row):\n",
    "    if pd.isna(row['CH06']): # Si 'CH06' es NaN, devolver la mediana correspondiente del nivel educativo\n",
    "        return edad_por_nivel.get(row['NIVEL_ED'], row['CH06'])\n",
    "    return row['CH06']\n",
    "\n",
    "# Aplicamps la función para rellenar los NaN en 'CH06'\n",
    "final_data.loc[:, 'CH06'] = final_data.apply(rellenar_nan_edad, axis=1)\n",
    "\n",
    "# Verificamos que ya no quede ningún NaN\n",
    "nan_after = final_data['CH06'].isna().sum()\n",
    "print(f\"Cantidad de NaN en la columna CH06 después del relleno: {nan_after}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a05be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos los NaN de las que le faltaban pocos datos de la base original\n",
    "col_nan = ['CH07', 'CH08', 'IPCF','IX_TOT'] \n",
    "final_data = final_data.dropna(subset=col_nan)\n",
    "\n",
    "# Verificamos\n",
    "nan_after7 = final_data['CH07'].isna().sum()\n",
    "nan_after8 = final_data['CH08'].isna().sum()\n",
    "nan_afterIPCF = final_data['IPCF'].isna().sum()\n",
    "nan_afterIX_TOT = final_data['IX_TOT'].isna().sum()\n",
    "print(f\"Cantidad de NaN en la columna CH07 después del relleno: {nan_after7}\")\n",
    "print(f\"Cantidad de NaN en la columna CH08 después del relleno: {nan_after8}\")\n",
    "print(f\"Cantidad de NaN en la columna IPCF después del relleno: {nan_afterIPCF}\")\n",
    "print(f\"Cantidad de NaN en la columna IX_TOT después del relleno: {nan_afterIX_TOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d184f509",
   "metadata": {},
   "source": [
    "## Punto 4:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e938ec9b",
   "metadata": {},
   "source": [
    "3 variables relevantes para predecir individuos desocupados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9769e8fd",
   "metadata": {},
   "source": [
    "Variable 1: proporción de personas que trabajan en el hogar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de8aebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la variable OCUPADO\n",
    "final_data['OCUPADO'] = final_data['ESTADO'].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "# Calcular cantidad de ocupados por hogar\n",
    "final_data['CANT_OCUPADOS'] = final_data.groupby(['CODUSU', 'NRO_HOGAR'])['OCUPADO'].transform('sum')\n",
    "\n",
    "# Calcular proporción de ocupados\n",
    "final_data['PROP_OCUPADOS'] = final_data['CANT_OCUPADOS'] / final_data['IX_TOT']\n",
    "\n",
    "# Revisar el resultado\n",
    "print(final_data[['CODUSU', 'NRO_HOGAR', 'CANT_OCUPADOS', 'IX_TOT', 'PROP_OCUPADOS']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f0e3f2",
   "metadata": {},
   "source": [
    "Variable 2: Proporción de menores de edad en el hogar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1745acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear columna indicando si es menor de edad\n",
    "final_data['MENOR'] = final_data['CH06'].apply(lambda x: 1 if x < 18 else 0)\n",
    "\n",
    "# Calcular cantidad de menores por hogar\n",
    "final_data['CANT_MENORES'] = final_data.groupby(['CODUSU', 'NRO_HOGAR'])['MENOR'].transform('sum')\n",
    "\n",
    "# Calcular proporción de menores en el hogar\n",
    "final_data['PROP_MENORES'] = final_data['CANT_MENORES'] / final_data['IX_TOT']\n",
    "\n",
    "# Visualizar la variable\n",
    "print(final_data[['CODUSU', 'NRO_HOGAR', 'CANT_MENORES', 'IX_TOT', 'PROP_MENORES']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5829f8",
   "metadata": {},
   "source": [
    "Variable 3: Dependencia económica del hogar. Esta calcula la proporción de habitantes inactivos vs activos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f182bc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear columnas para identificar inactivos y activos\n",
    "final_data['INACTIVO'] = final_data['CAT_INAC'].apply(lambda x: 1 if not pd.isna(x) else 0)\n",
    "final_data['ACTIVO'] = final_data['CAT_OCUP'].apply(lambda x: 1 if not pd.isna(x) else 0)\n",
    "\n",
    "# Calcular total de inactivos y activos por hogar\n",
    "final_data['CANT_INACTIVOS'] = final_data.groupby(['CODUSU', 'NRO_HOGAR'])['INACTIVO'].transform('sum')\n",
    "final_data['CANT_ACTIVOS'] = final_data.groupby(['CODUSU', 'NRO_HOGAR'])['ACTIVO'].transform('sum')\n",
    "\n",
    "# Calcular relación de dependencia económica\n",
    "final_data['DEPENDENCIA_ECONOMICA'] = final_data['CANT_INACTIVOS'] / (final_data['CANT_ACTIVOS'] + 1)  # +1 para evitar división por 0\n",
    "\n",
    "# Visualizar la variable\n",
    "print(final_data[['CODUSU', 'NRO_HOGAR', 'CANT_INACTIVOS', 'CANT_ACTIVOS', 'DEPENDENCIA_ECONOMICA']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e91795",
   "metadata": {},
   "source": [
    "Variable 4: Nivel educativo promedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977e37a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir niveles educativos en valores numéricos (si no lo están ya)\n",
    "niveles_educativos = {\n",
    "    'Sin instrucción': 0,\n",
    "    'Primaria Incompleta': 1,\n",
    "    'Primaria Completa': 2,\n",
    "    'Secundaria Incompleta': 3,\n",
    "    'Secundaria Completa': 4,\n",
    "    'Superior Universitaria Incompleta': 5,\n",
    "    'Superior Universitaria Completa': 6,\n",
    "    'Ns./Nr.': None  # O manejarlo como 0 si prefieres\n",
    "}\n",
    "\n",
    "final_data['NIVEL_ED_NUM'] = final_data['NIVEL_ED'].replace(niveles_educativos)\n",
    "\n",
    "# Calcular promedio educativo por hogar\n",
    "final_data['EDUC_PROMEDIO'] = final_data.groupby(['CODUSU', 'NRO_HOGAR'])['NIVEL_ED_NUM'].transform('mean')\n",
    "\n",
    "# Visualizar la variable\n",
    "print(final_data[['CODUSU', 'NRO_HOGAR', 'NIVEL_ED_NUM', 'EDUC_PROMEDIO']].drop_duplicates(subset=['CODUSU', 'NRO_HOGAR']).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fcd946",
   "metadata": {},
   "source": [
    "## Punto 5:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5c4521",
   "metadata": {},
   "source": [
    "Estadísitca descriptiva de 3 variables de la encuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fafd794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 1. Estadísticas descriptivas de CH06 (Edad) ---\n",
    "print(\"Estadísticas descriptivas de la edad (CH06):\")\n",
    "print(final_data['CH06'].describe())\n",
    "\n",
    "# --- 2. Frecuencias y proporciones de NIVEL_ED ---\n",
    "print(\"\\nFrecuencias y proporciones de NIVEL_ED:\")\n",
    "nivel_ed_frecuencias = final_data['NIVEL_ED'].value_counts()\n",
    "nivel_ed_proporciones = final_data['NIVEL_ED'].value_counts(normalize=True) * 100\n",
    "print(nivel_ed_frecuencias)\n",
    "print(nivel_ed_proporciones)\n",
    "\n",
    "# --- 3. Frecuencias y proporciones de CAT_INAC ---\n",
    "print(\"\\nFrecuencias y proporciones de CAT_INAC:\")\n",
    "cat_inac_frecuencias = final_data['CAT_INAC'].value_counts()\n",
    "cat_inac_proporciones = final_data['CAT_INAC'].value_counts(normalize=True) * 100\n",
    "print(cat_inac_frecuencias)\n",
    "print(cat_inac_proporciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238a6f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario para mapear los valores de NIVEL_ED\n",
    "niveles_educativos = {\n",
    "    1: 'Primaria Incom',\n",
    "    2: 'Primaria Com',\n",
    "    3: 'Secundaria Incom',\n",
    "    4: 'Secundaria Comp',\n",
    "    5: 'Universitaria Incom',\n",
    "    6: 'Universitaria Com',\n",
    "    7: 'Sin instrucción',\n",
    "    9: 'Ns./Nr.'\n",
    "}\n",
    "\n",
    "# Cambiar los índices de nivel_ed_frecuencias a etiquetas\n",
    "nivel_ed_frecuencias.index = nivel_ed_frecuencias.index.map(niveles_educativos)\n",
    "\n",
    "# Graficar NIVEL_ED con etiquetas descriptivas\n",
    "plt.figure(figsize=(8, 4))\n",
    "nivel_ed_frecuencias.plot(kind='bar', color='skyblue', title='Distribución de Nivel Educativo')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.xlabel('Nivel Educativo')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc298324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario para mapear los valores de CAT_INAC\n",
    "categorias_inactividad = {\n",
    "    1: 'Jubilado/pensionado',\n",
    "    2: 'Rentista',\n",
    "    3: 'Estudiante',\n",
    "    4: 'Ama de casa',\n",
    "    5: 'Menor de 6 años',\n",
    "    6: 'Discapacitado',\n",
    "    7: 'Otros'\n",
    "}\n",
    "\n",
    "# Filtrar las frecuencias para excluir el valor 0\n",
    "cat_inac_frecuencias_sin_cero = cat_inac_frecuencias[cat_inac_frecuencias.index != 0]\n",
    "\n",
    "# Cambiar los índices de cat_inac_frecuencias_sin_cero a etiquetas\n",
    "cat_inac_frecuencias_sin_cero.index = cat_inac_frecuencias_sin_cero.index.map(categorias_inactividad)\n",
    "\n",
    "# Graficar CAT_INAC con etiquetas descriptivas\n",
    "plt.figure(figsize=(8, 4))\n",
    "cat_inac_frecuencias_sin_cero.plot(kind='bar', color='salmon', title='Distribución de Categoría de Inactividad (sin 0)')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.xlabel('Categoría de Inactividad')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c82f23",
   "metadata": {},
   "source": [
    "## Parte 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46586ffd",
   "metadata": {},
   "source": [
    "Punto 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7709b65b",
   "metadata": {},
   "source": [
    "Partimos la base en entrenamiento y prueba\n",
    "\n",
    "1) Para cada año,partan la base respondieron en una base de prueba y una de entrenamiento (X_train, y_train, X_test, y_test) utilizando el comando train_test_split. La base de entrenamiento debe comprender el 70% de los datos, y la semilla a utilizar (random state instance) debe ser 101. Establezca a desocupado como su variable dependiente en la base de entrenamiento (vector y). El resto de las variables serán las variables independientes (matriz X). Recuerden agregar la columna de unos (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff5dcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar datos por año\n",
    "data_2004 = final_data[final_data['ANO4'] == 2004]\n",
    "data_2024 = final_data[final_data['ANO4'] == 2024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301481ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear variable DESOCUPADO\n",
    "for df in [data_2004, data_2024]:\n",
    "    df['DESOCUPADO'] = df['ESTADO'].apply(lambda x: 1 if x == 2 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c594e8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#Queda como varible dependiente \"DESOCUPADO\" y el resto de variables con impacto en dicha varible serán las dependientes \n",
    "# Para 2004\n",
    "y_2004 = respondieron_2004['DESOCUPADO']\n",
    "# todas las columnas menos desocupado\n",
    "X_2004 = respondieron_2004[['CH04', 'CH06', 'CH07', 'CH08', 'NIVEL_ED', 'ESTADO', 'CAT_INAC', 'IPCF', 'MENOR', 'OCUPADO', 'INACTIVO', 'ACTIVO', 'DEPENDENCIA_ECONOMICA', 'EDUC_PROMEDIO']]\n",
    "\n",
    "# Partición\n",
    "X_train_2004, X_test_2004, y_train_2004, y_test_2004 = train_test_split(X_2004, y_2004, test_size=0.3, random_state=101)\n",
    "\n",
    "# Columna de unos\n",
    "X_train_2004 = pd.concat([pd.Series(1, index=X_train_2004.index, name=\"Intercepto\"), X_train_2004], axis=1)\n",
    "X_test_2004 = pd.concat([pd.Series(1, index=X_test_2004.index, name=\"Intercepto\"), X_test_2004], axis=1)\n",
    "\n",
    "\n",
    "# Para 2024\n",
    "y_2024 = respondieron_2024['DESOCUPADO']\n",
    "# todas las columnas menos desocupado\n",
    "X_2024 = respondieron_2024[['CH04', 'CH06', 'CH07', 'CH08', 'NIVEL_ED', 'ESTADO', 'CAT_INAC', 'IPCF', 'MENOR', 'OCUPADO', 'INACTIVO', 'ACTIVO', 'DEPENDENCIA_ECONOMICA', 'EDUC_PROMEDIO']]\n",
    "\n",
    "# Partición\n",
    "X_train_2024, X_test_2024, y_train_2024, y_test_2024 = train_test_split(X_2024, y_2024, test_size=0.3, random_state=101)\n",
    "\n",
    "# Columna de unos\n",
    "X_train_2024 = pd.concat([pd.Series(1, index=X_train_2024.index, name=\"Intercepto\"), X_train_2024], axis=1)\n",
    "X_test_2024 = pd.concat([pd.Series(1, index=X_test_2024.index, name=\"Intercepto\"), X_test_2024], axis=1)\n",
    "\n",
    "# Convertimos la columna CH07 a variables dummy\n",
    "X_2004 = pd.get_dummies(X_2004, columns=['ESTADO'], drop_first=True)\n",
    "X_2024 = pd.get_dummies(X_2024, columns=['ESTADO'], drop_first=True)\n",
    "X_2004 = pd.get_dummies(X_2004, columns=['CH07'], drop_first=True)\n",
    "X_2024 = pd.get_dummies(X_2024, columns=['CH07'], drop_first=True)\n",
    "X_2004 = pd.get_dummies(X_2004, columns=['NIVEL_ED'], drop_first=True)\n",
    "X_2024 = pd.get_dummies(X_2024, columns=['NIVEL_ED'], drop_first=True)\n",
    "X_2004 = pd.get_dummies(X_2004, columns=['CH08'], drop_first=True)\n",
    "X_2024 = pd.get_dummies(X_2024, columns=['CH08'], drop_first=True)\n",
    "X_2004 = pd.get_dummies(X_2004, columns=['CH04'], drop_first=True)\n",
    "X_2024 = pd.get_dummies(X_2024, columns=['CH04'], drop_first=True)\n",
    "X_2004 = pd.get_dummies(X_2004, columns=['CAT_INAC'], drop_first=True)\n",
    "X_2024 = pd.get_dummies(X_2024, columns=['CAT_INAC'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cab835",
   "metadata": {},
   "source": [
    "Para regresión logística, implementen la penalidad, L1 como la de LASSO y L2 como la de Ridge con λ = 1 (como en la Tutorial 10), usando la opción penalty y reporten la matriz de confusión, la curva ROC, los valores de AUC y de Accuracy para cada año.1 ¿Cómo cambiaron los resultados con respecto al TP3? ¿La performance de regresión logística con regularización es mejor o peor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292c25be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
